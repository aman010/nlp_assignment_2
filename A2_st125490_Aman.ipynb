{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1651afc1",
   "metadata": {},
   "source": [
    "# A2\n",
    "**The notebook is with two model bi-directional and Attention-mechanism with simple lstm, the negative sampling and inference code is taken from chat gpt**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "id": "6b76a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required libraries\n",
    "import torchtext\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from collections import Counter\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import collections\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "# !pip install -U torchtext==0.6   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "78b38838-8175-4f5d-8006-22753e9e9791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = 'cuda:1' if torch.cuda.is_available() else 'cpu'\n",
    "# print(device, torch.cuda.get_device_name(0))\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdeb2cee-5be7-4423-84c6-5d4a90067cef",
   "metadata": {},
   "source": [
    "**Switched to cpu since gpu with smaller sample size take lot of time**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd7de4a",
   "metadata": {},
   "source": [
    "**The book dataset was taken from https://www.kaggle.com/datasets/shubhammaindola/harry-potter-books**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "b1ae6811",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('books/Book1.txt', encoding=\"utf8\") as f:\n",
    "    book1 = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "id": "74a7020e-b01e-433d-9f15-fed3204e568d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#0: / THE BOY WHO LIVED Mr. and Mrs. Dursley, of number four, Privet Drive, were proud to say that they were perfectly normal, thank you very much.\n",
      "#1: They were the last people you’d expect to be involved in anything strange or mysterious, because they just didn’t hold with such nonsense.\n",
      "#2: Mr. Dursley was the director of a firm called Grunnings, which made drills.\n",
      "#3: He was a big, beefy man with hardly any neck, although he did have a very large mustache.\n",
      "#4: Mrs. Dursley was thin and blonde and had nearly twice the usual amount of neck, which came in very useful as she spent so much of her time craning over garden fences, spying on the neighbors.\n",
      "#5: The Dursley s had a small son called Dudley and in their opinion there was no finer boy anywhere.\n",
      "#6: The Dursleys had everything they wanted, but they also had a secret, and their greatest fear was that somebody would discover it.\n",
      "#7: They didn’t think they could bear it if anyone found out about the Potters.\n",
      "#8: Mrs. Potter was Mrs. Dursley’s sister, but they hadn’t Page | 2 Harry Potter and the Philosophers Stone - J.K. Rowling met for several years; in fact, Mrs. Dursley pretended she didn’t have a sister, because her sister and her good-for-nothing husband were as unDursleyish as it was possible to be.\n",
      "#9: The Dursleys shuddered to think what the neighbors would say if the Potters arrived in the street.\n",
      "#10: The Dursleys knew that the Potters had a small son, too, but they had never even seen him.\n",
      "#11: This boy was another good reason for keeping the Potters away; they didn’t want Dudley mixing with a child like that.\n",
      "#12: When Mr. and Mrs. Dursley woke up on the dull, gray Tuesday our story starts, there was nothing about the cloudy sky outside to suggest that strange and mysterious things would soon be happening all over the country.\n",
      "#13: Mr. Dursley hummed as he picked out his most boring tie for work, and Mrs. Dursley gossiped away happily as she wrestled a screaming Dudley into his high chair.\n",
      "#14: None of them noticed a large, tawny owl flutter past the window.\n",
      "#15: At half past eight, Mr. Dursley picked up his briefcase, pecked Mrs. Dursley on the cheek, and tried to kiss Dudley good-bye but missed, because Dudley was now having a tantrum and throwing his cereal at the walls.\n",
      "#16: “Little tyke,” chortled Mr. Dursley as he left the house.\n",
      "#17: He got into his car and backed out of number four’s drive.\n",
      "#18: It was on the corner of the street that he noticed the first sign of something peculiar — a cat reading a map.\n",
      "#19: For a second, Mr. Dursley didn’t realize what he had seen — then he jerked his head around to look again.\n"
     ]
    }
   ],
   "source": [
    "#remove extra space\n",
    "book1 = re.sub(r'(Page\\s*\\d+)', '' , book1)\n",
    "book1 = re.sub(r'\\s+', ' ', book1).strip()\n",
    "# split text in sentences\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt_tab')\n",
    "book1_split = sent_tokenize(book1)\n",
    "for i, sentence in enumerate(book1_split[:20]):\n",
    "    print(f\"#{i}: {sentence}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "id": "8f08f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_merge():\n",
    "    re_ = {\"sentence\" : [],\"Book\" : []}\n",
    "    \n",
    "    for i in range(1, 7):\n",
    "        with open(f\"{'books/Book'}{i}.txt\", encoding=\"utf8\") as f:\n",
    "            book = f.read()\n",
    "        #clean the white spaces and numbers\n",
    "        book = re.sub(r'(Page\\s*\\d+)', '' , book)\n",
    "        book = re.sub(r'\\s+', ' ', book).strip()\n",
    "        _split = sent_tokenize(book)\n",
    "        \n",
    "        idx = np.repeat(i, len(_split))\n",
    "        re_[\"sentence\"].extend(_split)\n",
    "        re_['Book'].extend(idx)\n",
    "        \n",
    "    df = pd.DataFrame(re_)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "id": "0fc2203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the dataframe\n",
    "df = process_merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "id": "9408c2f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>Book</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/ THE BOY WHO LIVED Mr. and Mrs. Dursley, of n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>They were the last people you’d expect to be i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mr. Dursley was the director of a firm called ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>He was a big, beefy man with hardly any neck, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mrs. Dursley was thin and blonde and had nearl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Dursley s had a small son called Dudley an...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The Dursleys had everything they wanted, but t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>They didn’t think they could bear it if anyone...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mrs. Potter was Mrs. Dursley’s sister, but the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The Dursleys shuddered to think what the neigh...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  Book\n",
       "0  / THE BOY WHO LIVED Mr. and Mrs. Dursley, of n...     1\n",
       "1  They were the last people you’d expect to be i...     1\n",
       "2  Mr. Dursley was the director of a firm called ...     1\n",
       "3  He was a big, beefy man with hardly any neck, ...     1\n",
       "4  Mrs. Dursley was thin and blonde and had nearl...     1\n",
       "5  The Dursley s had a small son called Dudley an...     1\n",
       "6  The Dursleys had everything they wanted, but t...     1\n",
       "7  They didn’t think they could bear it if anyone...     1\n",
       "8  Mrs. Potter was Mrs. Dursley’s sister, but the...     1\n",
       "9  The Dursleys shuddered to think what the neigh...     1"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# see the first 10 rows of the dataframe to validate they match the first 10 sentences of the first book\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e26b4a48-cefe-46e6-a23e-c782a371622e",
   "metadata": {},
   "source": [
    "## preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "058cdd7d-ac9b-45c0-a099-349328e4dde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. tokenization\n",
    "corpus = df['sentence']\n",
    "corpus = [sent.split(\" \") for sent in corpus]\n",
    "df['sentence'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "id": "94b8ad4a-220a-4d18-af8a-0e7325c6669d",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "def rpuncst(x):\n",
    "     # Remove punctuation and stopwords\n",
    "    # tokens = [token.lower() for token in tokens]\n",
    "    # Apply stemming to each token\n",
    "    tokens = [token for token in x if token.isalnum() and token.lower() not in stop_words]    \n",
    "    return tokens\n",
    "\n",
    "corpus = df['sentence']\n",
    "corpus=corpus.apply(lambda x: rpuncst(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "id": "1b45c4f8-9df0-4cae-821f-45bb5f59aa63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        [BOY, LIVED, number, Privet, proud, say, perfe...\n",
       "1        [last, people, expect, involved, anything, str...\n",
       "2                  [Dursley, director, firm, called, made]\n",
       "3                    [beefy, man, hardly, although, large]\n",
       "4        [Dursley, thin, blonde, nearly, twice, usual, ...\n",
       "                               ...                        \n",
       "52619                                     [whatever, said]\n",
       "52620    [going, come, round, mum, house, anything, eve...\n",
       "52621                                         [miss, said]\n",
       "52622    [hand, closed, automatically, around, fake, sp...\n",
       "52623    [Page, 730, Harry, Potter, Half, Blood, Prince...\n",
       "Name: sentence, Length: 52624, dtype: object"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "87102e78-01c0-463b-a7f1-464daa203a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a dataset loader\n",
    "#* split the text into the input sequence length \n",
    "# problem with this approach is that we cannot split more than the length of the document if it is 7 then not more than 7 length each document will split into\n",
    "# further we create padding pas pack_padding_sequence\n",
    "\n",
    "class SimpleTextDataset(Dataset):\n",
    "    def __init__(self, vocab, corpus, seq_len):\n",
    "    \n",
    "        self.vocab = vocab\n",
    "        self.corpus = corpus\n",
    "        self.seq_len = seq_len\n",
    "\n",
    "    def __len__(self):\n",
    "        # Calculate the total number of subsequences\n",
    "        total_len = 0\n",
    "        for sentence in self.corpus:\n",
    "            total_len += len(sentence) - self.seq_len  # Number of valid subsequences from each sentence\n",
    "        return max(total_len, 0)  # Ensure it's non-negative\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Find the corresponding sentence and index for the given idx\n",
    "        total_len = 0\n",
    "        for sentence in self.corpus:\n",
    "            sentence_len = len(sentence)\n",
    "            if total_len + sentence_len > idx:\n",
    "                start_idx = idx - total_len\n",
    "                end_idx = start_idx + self.seq_len\n",
    "                \n",
    "                # Ensure we don't go out of bounds if seq_len is greater than remaining sentence length\n",
    "                text = sentence[start_idx:end_idx]\n",
    "                target = sentence[start_idx + 1:end_idx + 1] if end_idx <= len(sentence) else sentence[start_idx + 1:] + [self.vocab.get('<pad>', 0)] * (end_idx - len(sentence))\n",
    "                \n",
    "                break\n",
    "            total_len += sentence_len\n",
    "        \n",
    "        # Convert text and target to tensors using vocab\n",
    "        text_tensor = torch.tensor([self.vocab.get(word, self.vocab['<unk>']) for word in text], dtype=torch.long)\n",
    "        target_tensor = torch.tensor([self.vocab.get(word, self.vocab['<unk>']) for word in target], dtype=torch.long)\n",
    "        \n",
    "        return {'text': text_tensor, 'target': target_tensor}\n",
    "\n",
    "\n",
    "\n",
    "    # def __getitem__(self, idx):\n",
    "    #     text = self.texts[idx]\n",
    "        \n",
    "    #     # Convert tokens to indices based on the vocabulary\n",
    "    #     token_ids = [self.vocab.get(token, self.vocab['<unk>']) for token in text]\n",
    "        \n",
    "    #     # Convert the token list to a PyTorch tensor\n",
    "    #     token_tensor = torch.tensor(token_ids, dtype=torch.long)\n",
    "        \n",
    "    #     return {'text': token_tensor, 'length': len(token_tensor)}\n",
    "\n",
    "# Vocabulary creation (map each word to a unique index)\n",
    "def build_vocab(texts):\n",
    "    counter = Counter()\n",
    "    for text in texts:\n",
    "        counter.update(text)  # Count word occurrences in the tokenized sentences\n",
    "    vocab = {word: idx + 2 for idx, (word, _) in enumerate(counter.items())}  # Starting index from 2\n",
    "    vocab['<pad>'] = 0  # Padding token (if ever needed)\n",
    "    vocab['<unk>'] = 1  # Unknown token\n",
    "    return vocab\n",
    "\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "\n",
    "def collate_fn(batch):\n",
    "    # Sort the batch by sequence length (longest first)\n",
    "    batch = sorted(batch, key=lambda x: len(x['text']), reverse=True)\n",
    "\n",
    "    # Get the text and targets\n",
    "    texts = [item['text'] for item in batch]\n",
    "    targets = [item['target'] for item in batch]\n",
    "\n",
    "    # Convert lengths to a tensor\n",
    "    lengths_tensor = torch.tensor([len(x) for x in texts], dtype=torch.long)\n",
    "\n",
    "    # Pad the sequences to make them all the same length\n",
    "    padded_texts = pad_sequence(texts, batch_first=True, padding_value=0)\n",
    "    padded_targets = pad_sequence(targets, batch_first=True, padding_value=0)\n",
    "\n",
    "    # Ensure target length matches input length after padding\n",
    "    target_length = padded_texts.size(1)\n",
    "    if padded_targets.size(1) < target_length:\n",
    "        padded_targets = torch.cat([padded_targets, torch.zeros(len(batch), target_length - padded_targets.size(1)).long().to(padded_targets.device)], dim=1)\n",
    "\n",
    "    # Pack the padded sequences to inform the LSTM of the actual lengths\n",
    "    packed_input = pack_padded_sequence(padded_texts, lengths_tensor, batch_first=True, enforce_sorted=False)\n",
    "\n",
    "    return {\n",
    "        'text': packed_input,   # Return packed text sequences\n",
    "        'target': padded_targets,   # Return padded target sequences (next token)\n",
    "        'length': lengths_tensor  # Lengths of each sequence\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "686ec773-1dd5-43de-a89f-803d1862ca1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Build the vocabulary from the tokenized sentences\n",
    "vocab = build_vocab(corpus)\n",
    "\n",
    "# Create the dataset (without padding)\n",
    "dataset = SimpleTextDataset(vocab, corpus, seq_len=3)\n",
    "\n",
    "# Create the DataLoader to load data in batches\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True, collate_fn=collate_fn)\n",
    "\n",
    "# # Iterate through the DataLoader\n",
    "for batch in dataloader:\n",
    "    print(batch['text'])\n",
    "    # print(f\"Batch lengths: \\n{batch['length']}\")\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "94f62a43-9af4-4ae1-ad80-23973041ecce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7b4ad138fa70>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1c9767-f5f7-4263-9859-554f55a2b2d7",
   "metadata": {},
   "source": [
    "## build some bidirectional model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c540ef46-a1c9-4901-b6b8-e167917c982d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#the negative sampling is taken help from chatGPT\n",
    "\n",
    "class BiLSTM_model(nn.Module):\n",
    "    def __init__(self, input_dim, embed_dim, hidden_dim, output_dim, pad_idx, device, negative_samples=5):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=pad_idx)\n",
    "        self.hidden_dim = hidden_dim  # Define hidden_dim here\n",
    "        self.num_directions = 2  # BiLSTM means 2 directions (forward and backward)\n",
    "        \n",
    "        # BiLSTM with two directions (forward and backward)\n",
    "        self.forward_lstm = nn.LSTMCell(embed_dim, hidden_dim)\n",
    "        self.backward_lstm = nn.LSTMCell(embed_dim, hidden_dim)\n",
    "        \n",
    "        # Fully connected layer to map from hidden state to output dimension (vocab size)\n",
    "        self.fc = nn.Linear(hidden_dim * self.num_directions, output_dim)\n",
    "        \n",
    "        # Set the number of negative samples (default to 5)\n",
    "        self.negative_samples = negative_samples\n",
    "\n",
    "    def forward(self, packed_text, text_lengths):\n",
    "        # Unpack the sequence\n",
    "        padded_texts, _ = nn.utils.rnn.pad_packed_sequence(packed_text, batch_first=True, padding_value=0)\n",
    "        \n",
    "        # Embedding layer: Get word embeddings for the sequence\n",
    "        embedded = self.embedding(padded_texts)  # Shape: [batch_size, seq_len, embed_dim]\n",
    "        \n",
    "        batch_size, seq_len, _ = embedded.size()\n",
    "\n",
    "        # Initialize hidden states for BiLSTM (both forward and backward directions)\n",
    "        h_forward = torch.zeros(batch_size, self.hidden_dim).to(embedded.device)\n",
    "        c_forward = torch.zeros(batch_size, self.hidden_dim).to(embedded.device)\n",
    "\n",
    "        h_backward = torch.zeros(batch_size, self.hidden_dim).to(embedded.device)\n",
    "        c_backward = torch.zeros(batch_size, self.hidden_dim).to(embedded.device)\n",
    "\n",
    "        output_forward = []\n",
    "        output_backward = []\n",
    "\n",
    "        # Process forward LSTM\n",
    "        for t in range(seq_len):\n",
    "            h_forward, c_forward = self.forward_lstm(embedded[:, t, :], (h_forward, c_forward))\n",
    "            output_forward.append(h_forward.unsqueeze(1))\n",
    "\n",
    "        # Process backward LSTM\n",
    "        for t in range(seq_len - 1, -1, -1):\n",
    "            h_backward, c_backward = self.backward_lstm(embedded[:, t, :], (h_backward, c_backward))\n",
    "            output_backward.append(h_backward.unsqueeze(1))\n",
    "\n",
    "        # Concatenate forward and backward hidden states\n",
    "        output_forward = torch.cat(output_forward, dim=1)\n",
    "        output_backward = torch.cat(output_backward[::-1], dim=1)  # Reverse backward to match original order\n",
    "\n",
    "        # Concatenate forward and backward outputs\n",
    "        output = torch.cat((output_forward, output_backward), dim=-1)  # Shape: [batch_size, seq_len, hidden_dim * 2]\n",
    "        \n",
    "        # Final fully connected layer\n",
    "        output = self.fc(output.contiguous().view(batch_size * seq_len, -1))  # Flatten for the FC layer\n",
    "        \n",
    "        return output.view(batch_size, seq_len, -1)  # Reshape to [batch_size, seq_len, output_dim]\n",
    "\n",
    "    def negative_sampling_loss(self, output, target, vocab_size):\n",
    "        \n",
    "        batch_size, seq_len, _ = output.size()\n",
    "        \n",
    "        # Flatten the output and target for loss calculation\n",
    "        output_flat = output.view(-1, output.size(-1))  # Shape: [batch_size * seq_len, output_dim]\n",
    "        target_flat = target.view(-1)  # Shape: [batch_size * seq_len]\n",
    "\n",
    "        # Positive sample score: Use the true target words\n",
    "        positive_score = output_flat.gather(1, target_flat.unsqueeze(1))  # Shape: [batch_size * seq_len, 1]\n",
    "\n",
    "        # Negative sampling: randomly sample negative words\n",
    "        neg_samples = torch.randint(0, vocab_size, (batch_size * seq_len, self.negative_samples), device=output.device)\n",
    "\n",
    "        # Get the scores for the negative samples\n",
    "        negative_scores = output_flat.gather(1, neg_samples)  # Shape: [batch_size * seq_len, negative_samples]\n",
    "        \n",
    "        # Apply sigmoid to the positive and negative scores\n",
    "        positive_score = torch.sigmoid(positive_score)\n",
    "        negative_scores = torch.sigmoid(-negative_scores)\n",
    "\n",
    "        # Compute the loss: Positive log-likelihood + Negative log-likelihood\n",
    "        positive_loss = -torch.log(positive_score).sum()  # Sum over positive samples\n",
    "        negative_loss = -torch.log(negative_scores).sum()  # Sum over negative samples\n",
    "        \n",
    "        # Total loss (positive + negative)\n",
    "        loss = (positive_loss + negative_loss) / (batch_size * seq_len)\n",
    "\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "e8bf020f-a1bd-41b7-8328-807b35de5c6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n",
      "Output shape: torch.Size([10, 3, 128])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[105], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m model \u001b[38;5;241m=\u001b[39m BiLSTM_model(vocab_size, embed_dim, hidden_dim, output_dim, pad_idx, device)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Example input\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpacked_input\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtext_lengths\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlength\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:701\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    699\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 701\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    703\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    706\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called\n\u001b[1;32m    707\u001b[0m ):\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/dataloader.py:757\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    756\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 757\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    758\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    759\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     54\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[17], line 40\u001b[0m, in \u001b[0;36mSimpleTextDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     37\u001b[0m         target \u001b[38;5;241m=\u001b[39m sentence[start_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:end_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m end_idx \u001b[38;5;241m<\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(sentence) \u001b[38;5;28;01melse\u001b[39;00m sentence[start_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<pad>\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m0\u001b[39m)] \u001b[38;5;241m*\u001b[39m (end_idx \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mlen\u001b[39m(sentence))\n\u001b[1;32m     39\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     total_len \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m sentence_len\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# Convert text and target to tensors using vocab\u001b[39;00m\n\u001b[1;32m     43\u001b[0m text_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mget(word, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m<unk>\u001b[39m\u001b[38;5;124m'\u001b[39m]) \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m text], dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#this is just to test the batch loader\n",
    "embed_dim = 50\n",
    "hidden_dim = 64\n",
    "vocab_size = len(vocab)  # Example vocab size\n",
    "output_dim = 2 * hidden_dim  # BiLSTM, so output_dim is doubled\n",
    "pad_idx = 0  # Padding index (often 0)\n",
    "\n",
    "# Initialize model\n",
    "model = BiLSTM_model(vocab_size, embed_dim, hidden_dim, output_dim, pad_idx, device).to(device)\n",
    "\n",
    "# Example input\n",
    "for batch in dataloader:\n",
    "    packed_input = batch['text'].to(device)\n",
    "    text_lengths = batch['length'].to(device)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model(packed_input, text_lengths)\n",
    "    print(f\"Output shape: {output.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "888fd283-a094-489b-a262-cad6fbe7422d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.7873, Accuracy: 28.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Loss: 0.3421, Accuracy: 38.68%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Loss: 0.2484, Accuracy: 50.61%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Loss: 0.2038, Accuracy: 56.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Loss: 0.1777, Accuracy: 59.52%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Loss: 0.1585, Accuracy: 62.39%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Loss: 0.1437, Accuracy: 63.94%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Loss: 0.1329, Accuracy: 64.41%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Loss: 0.1236, Accuracy: 65.12%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Loss: 0.1184, Accuracy: 65.59%\n",
      "Training complete!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    }
   ],
   "source": [
    "def train(model, dataloader, optimizer, device, vocab_size, num_epochs=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        epoch_loss = 0  # To track the loss over the epoch\n",
    "        correct_predictions = 0  # Track the number of correct predictions\n",
    "        total_predictions = 0  # Track the total number of predictions\n",
    "        \n",
    "        # Loop over the DataLoader\n",
    "        for batch in tqdm(dataloader, desc=f\"Epoch {epoch + 1}/{num_epochs}\", leave=False):\n",
    "            # Get inputs and targets from the batch\n",
    "            text = batch['text'].to(device)\n",
    "            text_lengths = batch['length'].to(device)\n",
    "            target = batch['target'].to(device)  # Make sure to provide the target in your dataset\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            output = model(text, text_lengths)\n",
    "            \n",
    "            # Compute the negative sampling loss\n",
    "            loss = model.negative_sampling_loss(output, target, vocab_size)\n",
    "            \n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            \n",
    "            # Update the model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Track the loss\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Calculate accuracy\n",
    "            # Flatten output and target for easier comparison\n",
    "            output_flat = output.view(-1, output.size(-1))  # Shape: [batch_size * seq_len, output_dim]\n",
    "            target_flat = target.view(-1)  # Shape: [batch_size * seq_len]\n",
    "\n",
    "            # Get predicted word indices (the index with the highest score)\n",
    "            _, predicted_indices = output_flat.max(dim=1)  # Shape: [batch_size * seq_len]\n",
    "\n",
    "            # Compare predicted indices with target indices\n",
    "            correct_predictions += (predicted_indices == target_flat).sum().item()\n",
    "            total_predictions += target_flat.size(0)\n",
    "               # Compute average loss and accuracy\n",
    "\n",
    "        # Compute average loss and accuracy\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        accuracy = (correct_predictions / total_predictions) * 100 if total_predictions > 0 else 0.0\n",
    "        \n",
    "        # Print the loss and accuracy for the current epoch\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} - Loss: {avg_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n",
    "    \n",
    "    print(\"Training complete!\")\n",
    "\n",
    "# Example usage:\n",
    "# Define your model, optimizer, loss function, etc.\n",
    "vocab_size = 20031  # Example vocab size\n",
    "embed_dim = 50\n",
    "hidden_dim = 64\n",
    "output_dim = vocab_size  # Output dimension should match vocab size for prediction tasks\n",
    "pad_idx = 0\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Create the model\n",
    "model = BiLSTM_model(vocab_size, embed_dim, hidden_dim, output_dim, pad_idx, device, negative_samples=5).to(device)\n",
    "\n",
    "# Define optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming `dataloader` is ready (make sure your dataloader gives you a 'target' for the next-token prediction)\n",
    "train(model, dataloader, optimizer, device, vocab_size, num_epochs=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a0ce4b1a-a2e4-4323-ac6f-b95c1970c07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model,'Bi-directional-lstm.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce9061c4-670e-46cc-abd6-6e85e90f6002",
   "metadata": {},
   "source": [
    "## inference results of bi-direction-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76f776e3-ac20-4ead-b104-af0b52363369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BiLSTM_model(\n",
       "  (embedding): Embedding(20031, 50, padding_idx=0)\n",
       "  (forward_lstm): LSTMCell(50, 64)\n",
       "  (backward_lstm): LSTMCell(50, 64)\n",
       "  (fc): Linear(in_features=128, out_features=20031, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=torch.load('Bi-directional-lstm.pth', weights_only=False)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "73ea9517-b2e1-47e6-bb96-a7470e15980e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#part of the code is taken is from chat gpt\n",
    "def infer_with_sliding_window(model, input_sentence, vocab, device, seq_len=3, pad_idx=0):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    input_tensor = torch.tensor([vocab.get(word, vocab['<unk>']) for word in input_sentence], dtype=torch.long).to(device)\n",
    "    \n",
    "    # Pad the sequence to the required length (if necessary)\n",
    "    if len(input_tensor) < seq_len:\n",
    "        padding = torch.full((seq_len - len(input_tensor),), pad_idx, dtype=torch.long).to(device)\n",
    "        input_tensor = torch.cat((input_tensor, padding), dim=0).to(device)\n",
    "\n",
    "    # Sliding window: create chunks of size `seq_len` with stride of 1\n",
    "    chunks = [input_tensor[i:i+seq_len] for i in range(0, len(input_tensor) - seq_len + 1)]\n",
    "    \n",
    "    predicted_words = []\n",
    "\n",
    "    # For each chunk, predict the next word\n",
    "    for chunk in chunks:\n",
    "        # Pad the chunk if it's smaller than `seq_len` (i.e., the last chunk)\n",
    "        if len(chunk) < seq_len:\n",
    "            chunk = torch.cat((chunk, torch.full((seq_len - len(chunk),), pad_idx, dtype=torch.long).to(device)))\n",
    "\n",
    "        # Create a tensor for the current chunk and its length\n",
    "        chunk = chunk.unsqueeze(0)  # Add batch dimension (batch_size = 1)\n",
    "        lengths = torch.tensor([len(chunk)], dtype=torch.long)\n",
    "        \n",
    "        # Pack the input sequence (for variable-length sequences)\n",
    "        packed_input = torch.nn.utils.rnn.pack_padded_sequence(chunk, lengths, batch_first=True, enforce_sorted=False).to(device)\n",
    "\n",
    "        # Get the model's prediction for this chunk\n",
    "        with torch.no_grad():\n",
    "            output = model(packed_input, lengths)\n",
    "        \n",
    "        # Convert the output to a list of predicted tokens for each time step\n",
    "        output = output.squeeze(0)  # Remove batch dimension (batch_size = 1)\n",
    "        \n",
    "        # For the last token in the chunk, predict the next word\n",
    "        _, predicted_idx = output[-1].max(dim=-1)  # Get the predicted index for the last token\n",
    "        predicted_word = list(vocab.keys())[list(vocab.values()).index(predicted_idx.item())]\n",
    "        predicted_words.append(predicted_word)\n",
    "\n",
    "    return predicted_words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e0306834-551a-4de1-b37e-3637695260a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted words: ['said', 'terrible', 'Dad']\n"
     ]
    }
   ],
   "source": [
    "# Example usage:\n",
    "# Assuming the model is loaded, vocab is available, and device is set to 'cpu' or 'cuda'\n",
    "input_sentence = ['gotten', 'terrible', 'trouble', 'found', 'roof', 'school']\n",
    " # 'go!' # Example input sentence (tokenized)\n",
    "predicted_words = infer_with_sliding_window(model, input_sentence, vocab, \"cuda:0\", seq_len=4)\n",
    "\n",
    "print(f\"Predicted words: {predicted_words}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "5069feb1-4a38-46ea-815a-2f367abb5979",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dursley', 'always', 'sat', 'back', 'window', 'office', 'ninth']"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.loc[40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c682668f-c54b-4ea2-9d43-238cea200d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Mr.',\n",
       " 'Dursley',\n",
       " 'always',\n",
       " 'sat',\n",
       " 'with',\n",
       " 'his',\n",
       " 'back',\n",
       " 'to',\n",
       " 'the',\n",
       " 'window',\n",
       " 'in',\n",
       " 'his',\n",
       " 'office',\n",
       " 'on',\n",
       " 'the',\n",
       " 'ninth',\n",
       " 'floor.']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[40]['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "7b6efcfc-1a39-4015-9d93-3227204b4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def infer_last_word(model, input_sentence, vocab, device, pad_idx=0):\n",
    "   .    \n",
    "    # Ensure the model is in evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Tokenize and pad the input sequence\n",
    "    input_tensor = torch.tensor([vocab.get(word, vocab['<unk>']) for word in input_sentence], dtype=torch.long).to(device)\n",
    "    \n",
    "    # Pad the sequence to the required length (if necessary)\n",
    "    # if len(input_tensor) < seq_len:\n",
    "    #     padding = torch.full((seq_len - len(input_tensor),), pad_idx, dtype=torch.long).to(device)\n",
    "    #     input_tensor = torch.cat((input_tensor, padding), dim=0).to(device)\n",
    "\n",
    "    # Create tensor for the full input sentence\n",
    "    input_tensor = input_tensor.unsqueeze(0)  # Add batch dimension (batch_size = 1)\n",
    "    lengths = torch.tensor([len(input_tensor)], dtype=torch.long)\n",
    "    \n",
    "    # Pack the input sequence (for variable-length sequences)\n",
    "    packed_input = torch.nn.utils.rnn.pack_padded_sequence(input_tensor, lengths, batch_first=True, enforce_sorted=False).to(device)\n",
    "\n",
    "    # Get the model's prediction for the entire input sequence\n",
    "    with torch.no_grad():\n",
    "        output = model(packed_input, lengths)\n",
    "    \n",
    "    # Get the output corresponding to the last token (the last word in the sentence)\n",
    "    output = output.squeeze(0)  # Remove batch dimension (batch_size = 1)\n",
    "    \n",
    "    # For the last token in the sequence, predict the next word\n",
    "    # We get the output for the last token position\n",
    "    _, predicted_idx = output[-1].max(dim=-1)  # Get the predicted index for the last token\n",
    "    \n",
    "    # Convert the predicted index back to a word\n",
    "    predicted_word = list(vocab.keys())[list(vocab.values()).index(predicted_idx.item())]\n",
    "    \n",
    "    return predicted_word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "555e6218-ad3f-4f08-a2e2-97b143fb152e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sipped\n"
     ]
    }
   ],
   "source": [
    "input_sentence = ['Dursley', 'always', 'sat', 'back', 'window', 'office', 'ninth']\n",
    " # 'go!' # Example input sentence (tokenized)\n",
    "predicted_words = infer_last_word(model, input_sentence, vocab, \"cuda:0\")\n",
    "print(predicted_words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ef6e817a-0471-4ead-b50e-f9c86dcfc179",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def infer_random_sample(model, dataloader, criterion, device,seq_len=3):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():  # No gradients needed for inference\n",
    "        for batch in dataloader:\n",
    "            packed_input = batch['text']  # PackedSequence input (already packed)\n",
    "            target = batch['target']     # Target sequences\n",
    "            lengths = batch['length']     # Length of each sequence in the batch\n",
    "            \n",
    "            # Get the total number of sequences in the batch\n",
    "            batch_size = packed_input.batch_sizes[0]  # Number of sequences in the batch\n",
    "            \n",
    "            # Pick a random index for a sentence in the batch\n",
    "            random_idx = random.randint(0, batch_size - 1)\n",
    "\n",
    "            # Extract the lengths of the selected sample sequence\n",
    "            seq_length = lengths[random_idx].item()\n",
    "\n",
    "            # Unpack the packed input (so we can access individual sequences)\n",
    "            padded_input, _ = torch.nn.utils.rnn.pad_packed_sequence(packed_input, batch_first=True, padding_value=0)\n",
    "\n",
    "            # Extract the random sample sequence (no padding)\n",
    "            random_sample = padded_input[random_idx, :seq_length]  # Remove padding\n",
    "\n",
    "            # Forward pass through the model with the random sample\n",
    "            # We need to convert it back to a PackedSequence before passing through the model\n",
    "            packed_sample = torch.nn.utils.rnn.pack_padded_sequence(random_sample.unsqueeze(0), [seq_length], batch_first=True, enforce_sorted=False)\n",
    "            # Forward pass through the model\n",
    "            output = model(packed_sample, [seq_length])  # Assuming seq_len is passed in as a list\n",
    "\n",
    "            # Calculate the loss for this random sample\n",
    "            loss = criterion(output.view(-1, output.size(-1)), target[random_idx].view(-1))  # Flatten for loss computation\n",
    "\n",
    "            # Get predicted word indices (max over the output)\n",
    "            _, predicted_indices = output.max(dim=-1)  # Get indices of the predicted tokens\n",
    "\n",
    "            # Calculate accuracy for the random sample\n",
    "            correct = (predicted_indices.squeeze() == target[random_idx]).sum().item()\n",
    "            total = target[random_idx].numel()\n",
    "            accuracy = 100 * correct / total\n",
    "\n",
    "            print(f\"Random Sample Loss: {loss.item():.4f}\")\n",
    "            print(f\"Random Sample Accuracy: {accuracy:.2f}%\")\n",
    "            break  # We only need to compute for one random sample, break after first sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "efadf413-941f-4fcb-b029-be9b49e2f873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Sample Loss: 2.2029\n",
      "Random Sample Accuracy: 33.33%\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_LAUNCH_BLOCKING=1\n",
    "# torch.cuda.empty_cache()\n",
    "model=model.cpu()\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=0)  # Ignore padding index in loss computation\n",
    "device =\"cpu\"\n",
    "# Assuming you have a DataLoader `dataloader` prepared\n",
    "infer_random_sample(model, dataloader, criterion, device=device,seq_len=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1628d894-5021-4e3c-8ca2-7ee668d795b2",
   "metadata": {},
   "source": [
    "# Attension-mechansim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "8b10bca4-fd63-4a20-a140-4cb3a85ffc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "#let us build a very simple attension mechanism for classification tasks\n",
    "#the code is taken from the provided notebook\n",
    "class LSTM_GAtt(nn.Module):\n",
    "    def __init__(self, input_dim: int, embed_dim: int, hidden_dim: int, output_dim: int):\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(input_dim, embed_dim, padding_idx=pad_idx)\n",
    "        \n",
    "        # let's use pytorch's LSTM\n",
    "        self.lstm = nn.LSTM(embed_dim, \n",
    "                           hidden_dim, \n",
    "                           num_layers=4, \n",
    "                           bidirectional=True, \n",
    "                           dropout=.5,\n",
    "                           batch_first=True)\n",
    "        \n",
    "        # Linear Layer for binary classification \n",
    "        self.fc = nn.Linear(hidden_dim * 2, output_dim)\n",
    "        \n",
    "    def attention_net(self, lstm_output, hn):\n",
    "        \n",
    "        h_t      = hn.unsqueeze(2)\n",
    "        H_keys   = torch.clone(lstm_output)\n",
    "        H_values = torch.clone(lstm_output)\n",
    "        \n",
    "        alignment_score   = torch.bmm(H_keys, h_t).squeeze(2) # SHAPE : (bs, seq_len, 1)\n",
    "        \n",
    "        soft_attn_weights = F.softmax(alignment_score, 1) # SHAPE : (bs, seq_len, 1)\n",
    "        \n",
    "        context           = torch.bmm(H_values.transpose(1, 2), soft_attn_weights.unsqueeze(2)).squeeze(2) # SHAPE : (bs, hidden_size * num_directions)\n",
    "        \n",
    "        return context\n",
    "\n",
    "    def forward(self, text, text_lengths):\n",
    "\n",
    "        embedded = self.embedding(text) # SHAPE : (batch_size, seq_len, embed_dim)\n",
    "\n",
    "        lstm_output, (hn, cn) = self.lstm(embedded)\n",
    "        \n",
    "        # This is how we concatenate the forward hidden and backward hidden from Pytorch's BiLSTM\n",
    "        hn = torch.cat((hn[-2,:,:], hn[-1,:,:]), dim = 1)\n",
    "\n",
    "        attn_output = self.attention_net(lstm_output, hn)\n",
    "        output = self.fc(attn_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af14c052-806b-4a0f-903d-7d2dbd4a1efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trying on our old corpus for classfication tasks\n",
    "\n",
    "df=pd.read_parquet('0.parquet')\n",
    "df['text'] = df['text'].astype('unicode')\n",
    "corpus = df['text']\n",
    "corpus = [sent.split(\" \") for sent in corpus]\n",
    "df['text'] = corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "82d8749c-c10a-4fc8-b700-c78b4e552309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2067273/1004626873.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  corpus['text']=corpus['text'].apply(lambda x: rpuncst(x))\n"
     ]
    }
   ],
   "source": [
    "corpus = df[:1000]\n",
    "corpus['text']=corpus['text'].apply(lambda x: rpuncst(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e342723e-7fbd-40c1-b4eb-772c4e67b286",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[frustration, patient, repeat, experience, man...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[going, Goldberg, 10, think, one, 1st, patient...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[know, Goldberg, like, moving, let, tell, STAY...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[writing, review, give, heads, see, office, st...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[food, great, best, thing, wings, simply, best...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>[lot, bad, experiences, employees, rude, much,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>[location, caters, predominantly, low, income,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>[Barber, Shop, good, old, fashion, convo, spor...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>[problem, dry, cleaner, poor, counter, never, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>[Best, Cleaner, quality, clothing, want, cloth...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  label\n",
       "0    [frustration, patient, repeat, experience, man...      0\n",
       "1    [going, Goldberg, 10, think, one, 1st, patient...      1\n",
       "2    [know, Goldberg, like, moving, let, tell, STAY...      0\n",
       "3    [writing, review, give, heads, see, office, st...      0\n",
       "4    [food, great, best, thing, wings, simply, best...      1\n",
       "..                                                 ...    ...\n",
       "995  [lot, bad, experiences, employees, rude, much,...      0\n",
       "996  [location, caters, predominantly, low, income,...      0\n",
       "997  [Barber, Shop, good, old, fashion, convo, spor...      1\n",
       "998  [problem, dry, cleaner, poor, counter, never, ...      0\n",
       "999  [Best, Cleaner, quality, clothing, want, cloth...      1\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "bb915edc-d0eb-4b09-a294-fa8289737876",
   "metadata": {},
   "outputs": [],
   "source": [
    "flatten = lambda l: [item for sublist in l for item in sublist]\n",
    "#assign unique integer\n",
    "vocabs = list(set(flatten(corpus['text']))) #al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e0cd2a92-9264-4062-8f04-60dc5ffb44d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2index = {v:idx for idx, v in enumerate(vocabs)}\n",
    "vocabs.append('<UNK>')\n",
    "word2index['<UNK>'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "1bfaedfd-feaa-461f-8d23-e8e3c6e8225f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_seq=corpus['text'].tolist()\n",
    "#we will pad to the maximum values to keep things simple\n",
    "\n",
    "# pad_sequence(torch.tensor(list_seq)).size()\n",
    "padding_mat = []\n",
    "for sentence in list_seq:\n",
    "    padding_mat.append([word2index[word] for word in sentence])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "8bbd5f4e-5ec8-407e-a2a8-176975dc0267",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Padded batch:\n",
      "tensor([[6732, 4900, 7920,  ..., 5880, 2849, 4795],\n",
      "        [ 335, 5255,  230,  ..., 4677, 2973, 1754],\n",
      "        [5050, 5255, 5646,  ..., 5719, 6945, 7354],\n",
      "        ...,\n",
      "        [8601, 3541, 4795,  ..., 1072,  289,  280],\n",
      "        [1067, 7998, 5682,  ..., 3418, 1047, 8176],\n",
      "        [ 402, 4289, 7219,  ..., 5531, 6482, 2846]])\n"
     ]
    }
   ],
   "source": [
    "#create padding \n",
    "import torch\n",
    "\n",
    "def pad_batch_to_fixed_length(batch, seq_len, pad_idx=0, device='cpu'):\n",
    "    padded_batch = []\n",
    "\n",
    "    for seq in batch:\n",
    "        # Convert the sequence to a tensor\n",
    "        seq_tensor = torch.tensor(seq, dtype=torch.long).to(device)\n",
    "\n",
    "        # If sequence length is shorter than `seq_len`, pad it\n",
    "        if seq_tensor.size(0) < seq_len:\n",
    "            padding = torch.full((seq_len - seq_tensor.size(0),), pad_idx, dtype=torch.long).to(device)\n",
    "            padded_seq = torch.cat((seq_tensor, padding), dim=0)\n",
    "        else:\n",
    "            padded_seq = seq_tensor[:seq_len]  # Truncate if longer than seq_len\n",
    "\n",
    "        padded_batch.append(padded_seq)\n",
    "\n",
    "    # Stack the padded sequences into a tensor\n",
    "    padded_batch = torch.stack(padded_batch, dim=0)\n",
    "    return padded_batch\n",
    "\n",
    "# Example input (batch of tokenized sentences)\n",
    "\n",
    "# Desired fixed sequence length\n",
    "fixed_seq_len = 8\n",
    "pad_idx = 0  # Padding index\n",
    "device = 'cpu'  # Assuming you're using CPU\n",
    "\n",
    "# Pad the batch\n",
    "padded_batch = pad_batch_to_fixed_length(padding_mat, fixed_seq_len, pad_idx, device)\n",
    "\n",
    "print(\"Padded batch:\")\n",
    "print(padded_batch)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "b58c72a6-6610-4770-84ff-d3d0f067b24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_dim = \n",
    "\n",
    "# LSTM_GAtt(input_dim, embed_dim, hidden_dim, output_dim):\n",
    "\n",
    "input_dim = len(vocab)\n",
    "embed_dim = 50\n",
    "hidden_dim = 60 \n",
    "output_dim = 1\n",
    "model=LSTM_GAtt(input_dim, embed_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "8885b797-4493-4986-83cb-d412be6a1aa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LSTM_GAtt(\n",
       "  (embedding): Embedding(8744, 50, padding_idx=0)\n",
       "  (lstm): LSTM(50, 60, num_layers=4, batch_first=True, dropout=0.5, bidirectional=True)\n",
       "  (fc): Linear(in_features=120, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "8975a784-b8c2-4a36-9855-a1f89825163d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:35<00:00, 28.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 0.6899, Accuracy: 54.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:34<00:00, 28.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/10 - Loss: 0.6843, Accuracy: 57.10%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:35<00:00, 27.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/10 - Loss: 0.6271, Accuracy: 64.30%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:37<00:00, 26.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10 - Loss: 0.5668, Accuracy: 70.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:35<00:00, 28.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/10 - Loss: 0.5281, Accuracy: 73.70%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 29.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/10 - Loss: 0.4742, Accuracy: 79.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:34<00:00, 28.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10 - Loss: 0.4301, Accuracy: 80.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:36<00:00, 27.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/10 - Loss: 0.3739, Accuracy: 84.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:33<00:00, 29.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/10 - Loss: 0.3200, Accuracy: 87.90%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:34<00:00, 29.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/10 - Loss: 0.2591, Accuracy: 90.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Use BCEWithLogitsLoss for binary classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss_fn  = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    epoch_loss = 0  # To track the loss over the epoch\n",
    "    correct_predictions = 0  # Track the number of correct predictions\n",
    "    total_predictions = 0  # Track the total predictions\n",
    "    \n",
    "    # Iterate over each sequence in the padded_batch\n",
    "    for step_counter in tqdm(range(padded_batch.size(0))):  # Iterate through each row (sequence)\n",
    "        optimizer.zero_grad()  # Zero out gradients before the forward pass\n",
    "        \n",
    "        # Extract the current sequence and its corresponding label\n",
    "        batch_tensor = padded_batch[step_counter].unsqueeze(0).long().to(device)  # Add batch dimension\n",
    "        label = torch.tensor(corpus['label'].loc[step_counter], dtype=torch.float).to(device)  # Get the label for this sequence\n",
    "\n",
    "        # Get the length of the sequence (this should be the same across the batch)\n",
    "        seq_len = batch_tensor.size(1)  # The length of the sequence for this particular example\n",
    "\n",
    "        # Forward pass through the model\n",
    "        output = model(batch_tensor, torch.tensor([seq_len]).to(device))  # Pass through the model\n",
    "        \n",
    "        # No need to apply sigmoid here since BCEWithLogitsLoss expects raw logits\n",
    "        loss = loss_fn(output.squeeze(), label)  # Apply loss function directly on logits\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # Backpropagate and update weights\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate accuracy (sigmoid the output and compare with threshold)\n",
    "        output_prob = torch.sigmoid(output).squeeze()  # Apply sigmoid to get probabilities\n",
    "        \n",
    "        # If probability > 0.5, we predict class 1, else class 0\n",
    "        prediction = (output_prob > 0.5).float()\n",
    "        \n",
    "        # Update correct predictions and total predictions\n",
    "        correct_predictions += (prediction == label).sum().item()\n",
    "        total_predictions += 1 # Since batch size is 1, total_predictions is incremented by 1 each time\n",
    "        \n",
    "    # Calculate average loss and accuracy for the epoch\n",
    "    avg_loss = epoch_loss / padded_batch.size(0)  # Average loss over the epoch\n",
    "    accuracy = correct_predictions / total_predictions  # Accuracy for the epoch\n",
    "    \n",
    "    print(f\"Epoch {epoch + 1}/{epochs} - Loss: {avg_loss:.4f}, Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "1a3913b7-473d-4f15-b664-b10960616828",
   "metadata": {},
   "outputs": [],
   "source": [
    "#random sample\n",
    "sample=np.array(np.round(np.random.uniform(0,len(padding_mat),10)), dtype ='int')\n",
    "text=np.array(padded_batch)[sample]\n",
    "lable=np.array(corpus['label'])[sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "fb8194e8-3fb4-4e3e-814c-e60d8973eba9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded_batch.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "id": "6327cc30-254a-4a8b-8f1f-12180c372fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {'prediction':[], 'label':[],'text':[]}\n",
    "for i,t in enumerate(text):\n",
    "    te = torch.tensor(t, dtype=torch.long).unsqueeze(0)\n",
    "    size_ = te.size(1)\n",
    "    with torch.no_grad():\n",
    "        output = model(te, size_)\n",
    "        loss = loss_fn(output.squeeze().float(), torch.tensor(lable[i], dtype=torch.float))  # Apply loss function directly on logits\n",
    "        output_prob = torch.sigmoid(output).squeeze()  # Apply sigmoid to get probabilities\n",
    "        prediction = (output_prob > 0.5).float()\n",
    "        res['prediction'].append(prediction)\n",
    "        res['label'].append(lable[i])\n",
    "        res['text'].append(df['text'].loc[i])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "7058c6a0-e716-4312-b5b5-9434b1a2ba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,r in enumerate(res['text']):\n",
    "    res['text'][k]=''.join(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "45797c17-adb7-416a-b12c-ae7a28b52fa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>1</td>\n",
       "      <td>[Unfortunately,, the, frustration, of, being, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>1</td>\n",
       "      <td>[Been, going, to, Dr., Goldberg, for, over, 10...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, don't, know, what, Dr., Goldberg, was, lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>1</td>\n",
       "      <td>[I'm, writing, this, review, to, give, you, a,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>0</td>\n",
       "      <td>[All, the, food, is, great, here., But, the, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>1</td>\n",
       "      <td>[Wing, sauce, is, like, water., Pretty, much, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tensor(1.)</td>\n",
       "      <td>0</td>\n",
       "      <td>[Owning, a, driving, range, inside, the, city,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>0</td>\n",
       "      <td>[This, place, is, absolute, garbage..., , Half...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>0</td>\n",
       "      <td>[Before, I, finally, made, it, over, to, this,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>tensor(0.)</td>\n",
       "      <td>0</td>\n",
       "      <td>[I, drove, by, yesterday, to, get, a, sneak, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   prediction  label                                               text\n",
       "0  tensor(1.)      1  [Unfortunately,, the, frustration, of, being, ...\n",
       "1  tensor(1.)      1  [Been, going, to, Dr., Goldberg, for, over, 10...\n",
       "2  tensor(0.)      0  [I, don't, know, what, Dr., Goldberg, was, lik...\n",
       "3  tensor(1.)      1  [I'm, writing, this, review, to, give, you, a,...\n",
       "4  tensor(0.)      0  [All, the, food, is, great, here., But, the, b...\n",
       "5  tensor(0.)      1  [Wing, sauce, is, like, water., Pretty, much, ...\n",
       "6  tensor(1.)      0  [Owning, a, driving, range, inside, the, city,...\n",
       "7  tensor(0.)      0  [This, place, is, absolute, garbage..., , Half...\n",
       "8  tensor(0.)      0  [Before, I, finally, made, it, over, to, this,...\n",
       "9  tensor(0.)      0  [I, drove, by, yesterday, to, get, a, sneak, p..."
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "id": "636e9953-ad0a-4c2f-9595-8f74c01c67e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"Attention_weights\")\n",
    "torch.save(model, \"Attention_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "991805e2-1459-4671-9c74-2d87d596c90f",
   "metadata": {},
   "source": [
    "# final comparision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "id": "b1f8fa1c-7dea-4178-855e-c407d3d5570e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Traning loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bi-Directional-LSTM</td>\n",
       "      <td>0.1192</td>\n",
       "      <td>65</td>\n",
       "      <td>Next word prediction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Attention-lstm</td>\n",
       "      <td>0.2591</td>\n",
       "      <td>90</td>\n",
       "      <td>Classfication</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bi-Directional-50</td>\n",
       "      <td>0.0568</td>\n",
       "      <td>67</td>\n",
       "      <td>Next word prediction</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model Traning loss Accuracy                  Task\n",
       "0  Bi-Directional-LSTM       0.1192       65  Next word prediction\n",
       "1       Attention-lstm       0.2591       90         Classfication\n",
       "2    Bi-Directional-50       0.0568       67  Next word prediction"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "v=pd.DataFrame(columns =['Model', 'Traning loss',  'Accuracy', 'Task'])\n",
    "v['Model'] = ['Bi-Directional-LSTM', 'Attention-lstm', 'Bi-Directional-50']\n",
    "v['Traning loss'] = ['0.1192', '0.2591', ' 0.0568']\n",
    "v['Accuracy'] = ['65', '90', '67']\n",
    "v['Task'] = ['Next word prediction', 'Classfication', 'Next word prediction']\n",
    "display(v)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46580f6-27f3-4674-9088-097aad63ebb9",
   "metadata": {},
   "source": [
    "** Observation and challanges **\n",
    "* The Bi-directional-LSTM was hard to fit the model keeps on increasing the accuracy and loss tried various method to click gradient, then we tried negative sample\n",
    "* inference with Bi-LSTM is done in two ways although the model is next work prediction rolling window size prediction which gives a bit sensable results and last wors prediction which is again worst in performance\n",
    "* Tried to run the model for longer duration does not give any performance gain\n",
    "* learning rate is reduced to 0.001\n",
    "* Attention mechanism since produce the linear layer output in order to find the curitial word in a sentence to classify is intresting problem\n",
    "* The part of inferenc code and negative sampling is taken help from chatgpt , but it was the self idea to try"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
